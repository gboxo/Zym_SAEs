{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929764a6-0f0c-4b79-90d9-b6ddd7ec2eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atuin/b114cb/b114cb23/boxo/pSAE/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import pickle as pkl\n",
    "from peft import LoraConfig, inject_adapter_in_model\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc6dd3e-cc2b-4fb4-9f83-16f4354de50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(checkpoint, filepath, num_labels=1, mixed=False, full=False, deepspeed=True):\n",
    "    model, tokenizer = (\n",
    "        load_esm_model(checkpoint, num_labels, mixed, full, deepspeed)\n",
    "        if \"esm\" in checkpoint\n",
    "        else load_T5_model(checkpoint, num_labels, mixed, full, deepspeed)\n",
    "    )\n",
    "    non_frozen_params = torch.load(filepath)\n",
    "    for param_name, param in model.named_parameters():\n",
    "        if param_name in non_frozen_params:\n",
    "            param.data = non_frozen_params[param_name].data\n",
    "    return tokenizer, model\n",
    "\n",
    "\n",
    "def load_esm_model(checkpoint, num_labels, half_precision, full=False, deepspeed=True):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        checkpoint, num_labels=num_labels,\n",
    "        torch_dtype=torch.float16 if half_precision and deepspeed else None\n",
    "    )\n",
    "    if full:\n",
    "        return model, tokenizer\n",
    "\n",
    "    peft_config = LoraConfig(\n",
    "        r=4, lora_alpha=1, bias=\"all\", target_modules=[\"query\", \"key\", \"value\", \"dense\"]\n",
    "    )\n",
    "    model = inject_adapter_in_model(peft_config, model)\n",
    "    for param_name, param in model.classifier.named_parameters():\n",
    "        param.requires_grad = True\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d024d15f-7444-4498-9b3a-37445d8a9839",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"/home/woody/b114cb/b114cb23/models/esm2_t33_650M_UR50D\"\n",
    "tokenizer, model = load_model(\n",
    "    checkpoint,\n",
    "    \"/home/woody/b114cb/b114cb23/Filippo/alpha_amylase_activity_predictor/LoRa_esm2_3B/esm_GB1_finetuned.pth\",\n",
    "    num_labels=1\n",
    ")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
